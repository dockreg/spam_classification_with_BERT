{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Adaptations\n",
    "\n",
    "This notebook seeks to improve on the work from a simple google colab notebook model. This sentiment analysis model uses logistic regression and is trained and tested with data from the IMDB movie review dataset. The system obtains a ~77% accuracy and the goal of this notebook is to improve on this using two ideas while still using Logistic regression. The selected ideas for this task are to use *stop word removal* and *named entity recognition* and *masking*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsF8yRafNKjw"
   },
   "source": [
    "The IMDB dataset used in this notebook is available from the [huggingface datasets library](https://huggingface.co/datasets/imdb) and is well described in [Maas et al. 2011](https://aclanthology.org/P11-1015.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset / dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "yd0bLG6nOE4D",
    "outputId": "97c664b9-dd63-4e6c-8883-ed9354f31a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/dockreg/anaconda3/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: dill in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (4.62.2)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (4.8.1)\n",
      "Requirement already satisfied: xxhash in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: multiprocess in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: packaging in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (2021.8.1)\n",
      "Requirement already satisfied: aiohttp in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: pyyaml in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: filelock in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "3b94d8e360a44b6f83731af68677906e",
      "ba2e4cdda6a34b19b3f6715a7610404b",
      "5fb61b5ce17f478888f05d9b664f5712",
      "cdd09b420fc54b7583fb32a25c002666",
      "8be58c388ed84ceb901afb141a7b9c35",
      "aecef84787f74ca484558d5e790fd736",
      "bb006df01bdf4635a19524c409ae2a44",
      "6c5797f269fa4c22b76680d4c17510c3",
      "0d9e8798cb9a49c49e223f95ffe42472",
      "b4607a3bc9544578829f101921518328",
      "ee93ee8a3d414c72a70b35705083e8e6"
     ]
    },
    "id": "XOO5rQFHUg8D",
    "outputId": "bd68b963-ea2d-4efd-dbc2-9104d26ddbd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/dockreg/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfc822bfea545e895c91671c70a1896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n",
      "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"imdb\")\n",
    "print(raw_datasets['train'][0])\n",
    "print(raw_datasets['test'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enwDYpN7Hwgw"
   },
   "source": [
    "### Data Formatting\n",
    "\n",
    "Sci-kit learn is used in this notebookto transform the data into a list of input vectors to represent the documents and a list of associated output labels are also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8xfDeEMWq1o",
    "outputId": "5137262e-159c-4d01-8ba2-36961cb61638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "#train_dataset = raw_datasets['train'].shuffle(seed=42).select(range(25000))\n",
    "train_dataset = raw_datasets['train']\n",
    "train_data = []\n",
    "train_data_labels = []\n",
    "for item in train_dataset:\n",
    "    train_data.append(item['text'])\n",
    "    train_data_labels.append(item['label'])\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI6ab7wOIOu2"
   },
   "source": [
    "CountVectorizer is used to create an array of the most frequent words which is used as features. This creates a single array for each of the reviews representing the words present. The max_features is set to 200 which represents how many features we plan to use in this. The 200 most frequent words are appropriate for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vp3j80QKXMkg"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDYo_rZkXZUZ",
    "outputId": "76a4727b-74d2-4403-b8b7-48798efa5f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',max_features=200,lowercase=True)\n",
    "features = vectorizer.fit_transform(train_data)\n",
    "features_nd = features.toarray()\n",
    "print(len(features_nd))\n",
    "print(len(features_nd[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IgFqymeXcGzG"
   },
   "outputs": [],
   "source": [
    "# split data into 80/20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_nd,train_data_labels,train_size=0.8,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import/Train/Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Yn-H8cvpZMr9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TFPY4JrcZkFZ"
   },
   "outputs": [],
   "source": [
    "# model training\n",
    "log_model = log_model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xS22mi3sgr40"
   },
   "outputs": [],
   "source": [
    "# model testing\n",
    "y_pred = log_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ak_-Ah-Ig1bz",
    "outputId": "6d5eaf6b-9e87-43a8-80a1-c6d9ea9d0bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RkTD6YKJqyi"
   },
   "source": [
    "The logistic regression classifier has a ~77% accuracy for this task based on the test data which has been used as validation.\n",
    "To test the model a random selection of data is chosen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-FcQyXTM5ZX",
    "outputId": "c783682e-9a41-4b80-e7fc-a7e49f335e02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/dockreg/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b23cfeb68a931a8d.arrow\n"
     ]
    }
   ],
   "source": [
    "test_dataset = raw_datasets['test'].shuffle(seed=42).select(range(1000))\n",
    "test_data = []\n",
    "test_data_labels = []\n",
    "for item in test_dataset:\n",
    "    test_data.append(item['text'])\n",
    "    test_data_labels.append(item['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CvvuCc1vFubN"
   },
   "outputs": [],
   "source": [
    "# run the test data through the model\n",
    "test_pred=log_model.predict(vectorizer.transform(test_data).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiKVD8CeHH6I",
    "outputId": "4c238598-c8ae-4a7b-a1e6-7ad38f9e4325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_pred,test_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection of Misclassified Reviews\n",
    "\n",
    "To get a better understanding of the performance of the model so far, some of the incorrectly labelled reviews are inspected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_array = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "misclassified_samples = test_data_array[test_data_labels != test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = test_data_labels[test_pred!=test_data_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = test_pred[test_pred != test_data_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)\n",
    "prediction[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample: Positive\n",
    "### Predicted: Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample: Positive\n",
    "### Predicted: Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_samples[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample: Negative\n",
    "### Predicted: Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Porn legend Gregory Dark directs this cheesy horror flick that has Glen Jacobs (Kane from WWF/WWE/ whatever it calls itself nowadays) in his cinematic debut. He plays Jacob Goodknight, a blind serial killer who's forte is taking people's eyes out. The plot, be it as it may, has a group of troubled youths cleaning up the historical hotel that GoodKnight resides in and subsequently being offed by him. Hemmingway it's not. Starts of as fun dopey B-movie, but soon gets too tedious to be enjoyable. Glad I went in with pretty low expectations, but even those weren't met. How can you have a porn king directing and still suffer from a lack of nudity??? for shame.<br /><br />My Grade: D- <br /><br />Eye Candy: Samantha Noble bares her ass briefly\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_samples[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These reviews appear to be incorrectly misclassified due to a number of reasons. A number of issues arise from the use of positive words with negation. Another issue is the large number of stopwords which will cause issues with the accuracy of the predictions. These will also be inspected and removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The logistic regression sentiment classifier has a 74% accuracy for this task. The following section attempts to improve upon this by the use of two select methods. The chosen methods are:\n",
    "- Stop word removal\n",
    "- Name entity recognition\n",
    "\n",
    "#### Stop word removal\n",
    "\n",
    "Stop word removal is a useful technique for use in many Natural Language Processing (NLP) tasks. Stop words are frequently used words that don't add much syntactic context to the sentence but are needed for the fluid formation and understanding of the sentence. Examples of stop words are prepositions or articles such as 'and', 'the', 'in', 'by', etc. These can occupy a large amount of space within a document and in the case of the countVectoriser above these stop words may use up valuable space in the top 200 words when they provide little value to the predictive model in determining a positive or negative sentiment.\n",
    "Many different NLP libraries have lists of stop words which can be used to removed the stop words present in the text. For this task the spaCy library is used.\n",
    "\n",
    "#### Named Entity Recognition\n",
    "Named Entity Recognition (NER) is another useful technique that allows for the classification of named entities within a text. Named entities can be people, organisations, locations, countries, events, etc. These representations can unwantedly influence the performace of models and so there are a number of libraries that are available for the recognition of named entities that also allow for the tagging/masking of these to further the NLP task at hand. The NER library that is used in this task is spaCy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop word removal\n",
    "\n",
    "All of the movie reviews are of varying length. The longest review is inspected now to understand the occurance of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to help his brother, but the referee restrained him while Benoit and Guerrero ganged up on him in the corner. With Benoit stomping away on Bubba, Guerrero set up a table outside. Spike dashed into the ring and somersaulted over the top rope onto Guerrero on the outside! After recovering and taking care of Spike, Guerrero slipped a table into the ring and helped the Wolverine set it up. The tandem then set up for a double superplex from the middle rope which would have put Bubba through the table, but Spike knocked the table over right before his brother came crashing down! Guerrero and Benoit propped another table in the corner and tried to Irish Whip Spike through it, but Bubba dashed in and blocked his brother. Bubba caught fire and lifted both opponents into back body drops! Bubba slammed Guerrero and Spike stomped on the Wolverine from off the top rope. Bubba held Benoit at bay for Spike to soar into the Wassup! headbutt! Shortly after, Benoit latched Spike in the Crossface, but the match continued even after Spike tapped out. Bubba came to his brother's rescue and managed to sprawl Benoit on a table. Bubba leapt from the middle rope, but Benoit moved and sent Bubba crashing through the wood! But because his opponents didn't force him through the table, Bubba was allowed to stay in the match. The first man was eliminated shortly after, though, as Spike put Eddie through a table with a Dudley Dawg from the ring apron to the outside! Benoit put Spike through a table moments later to even the score. Within seconds, Bubba nailed a Bubba Bomb that put Benoit through a table and gave the Dudleys the win! Winner: Bubba Ray and Spike Dudley<br /><br />Match 2: Cruiserweight Championship Jamie Noble vs Billy Kidman Billy Kidman challenged Jamie Noble, who brought Nidia with him to the ring, for the Cruiserweight Championship. Noble and Kidman locked up and tumbled over the ring, but raced back inside and grappled some more. When Kidman thwarted all Noble's moves, Noble fled outside the ring where Nidia gave him some encouragement. The fight spread outside the ring and Noble threw his girlfriend into the challenger. Kidman tossed Nidia aside but was taken down with a modified arm bar. Noble continued to attack Kidman's injured arm back in the ring. Kidman's injured harm hampered his offense, but he continued to battle hard. Noble tried to put Kidman away with a powerbomb but the challenger countered into a facebuster. Kidman went to finish things with a Shooting Star Press, but Noble broke up the attempt. Kidman went for the Shooting Star Press again, but this time Noble just rolled out of harm's way. Noble flipped Kidman into a power bomb soon after and got the pin to retain his WWE Cruiserweight Championship! Winner: Jamie Noble<br /><br />Match 3: European Championship William Regal vs Jeff Hardy William Regal took on Jeff Hardy next in an attempt to win back the European Championship. Jeff catapulted Regal over the top rope then took him down with a hurracanrana off the ring apron. Back in the ring, Jeff hit the Whisper in the wind to knock Regal for a loop. Jeff went for the Swanton Bomb, but Regal got his knees up to hit Jeff with a devastating shot. Jeff managed to surprise Regal with a quick rollup though and got the pin to keep the European Championship! Regal started bawling at seeing Hardy celebrate on his way back up the ramp. Winner: Jeff Hardy<br /><br />Match 4: Chris Jericho vs John Cena Chris Jericho had promised to end John Cena's career in their match at Vengeance, which came up next. Jericho tried to teach Cena a lesson as their match began by suplexing him to the mat. Jericho continued to knock Cena around the ring until his cockiness got the better of him. While on the top rope, Jericho began to showboat and allowed Cena to grab him for a superplex! Cena followed with a tilt-a-whirl slam but was taken down with a nasty dropkick to the gut. The rookie recovered and hit a belly to belly suplex but couldn't put Y2J away. Jericho launched into the Lionsault but Cena dodged the move. Jericho nailed a bulldog and then connected on the Lionsault, but did not go for the cover. He goaded Cena to his feet so he could put on the Walls of Jericho. Cena had other ideas, reversing the move into a pin attempt and getting the 1-2-3! Jericho went berserk after the match. Winner: John Cena<br /><br />Match 5: Intercontinental Championship RVD vs Brock Lesnar via disqualification The Next Big Thing and Mr. Pay-Per-View tangled with the Intercontinental Championship on the line. Brock grabbed the title from the ref and draped it over his shoulder momentarily while glaring at RVD. Van Dam 's quickness gave Brock fits early on. The big man rolled out of the ring and kicked the steel steps out of frustration. Brock pulled himself together and began to take charge. With Paul Heyman beaming at ringside, Brock slammed RVD to the hard floor outside the ring. From there, Brock began to overpower RVD, throwing him with ease over the top rope. RVD landed painfully on his back, then had to suffer from having his spine cracked against the steel ring steps. The fight returned to the ring with Brock squeezing RVD around the ribs. RVD broke away and soon after leveled Brock with a kick to the temple. RVD followed with the Rolling Thunder but Brock managed to kick out after a two-count. The fight looked like it might be over soon as RVD went for a Five-Star Frog Splash. Brock, though, hoisted Van Dam onto his shoulder and went for the F-5, but RVD whirled Brock into a DDT and followed with the Frog Splash! He went for the pin, but Heyman pulled the ref from the ring! The ref immediately called for a disqualification and soon traded blows with Heyman! After, RVD leapt onto Brock from the top rope and then threatened to hit the Van Terminator! Heyman grabbed RVD's leg and Brock picked up the champ and this time connected with the F-5 onto a steel chair! Winner: RVD<br /><br />Match 6: Booker T vs the Big Show Booker T faced the Big Show one-on-one next. Show withstood Booker T's kicks and punches and slapped Booker into the corner. After being thrown from the ring, Booker picked up a chair at ringside, but Big Show punched it back into Booker's face. Booker tried to get back into the game by choking Show with a camera cable at ringside. Booker smashed a TV monitor from the Spanish announcers' position into Show's skull, then delivered a scissors kick that put both men through the table! Booker crawled back into the ring and Big Show staggered in moments later. Show grabbed Booker's throat but was met by a low blow and a kick to the face. Booker climbed the top rope and nailed a somersaulting leg drop to get the pin! Winner: Booker T<br /><br />Announcement: Triple H entered the ring to a thunderous ovation as fans hoped to learn where The Game would end up competing. Before he could speak, Eric Bishoff stopped The Game to apologize for getting involved in his personal business. If Triple H signed with RAW, Bischoff promised his personal life would never come into play again. Bischoff said he's spent the past two years networking in Hollywood. He said everyone was looking for the next breakout WWE Superstar, and they were all talking about Triple H. Bischoff guaranteed that if Triple H signed with RAW, he'd be getting top opportunities coming his way. Stephanie McMahon stepped out to issue her own pitch. She said that because of her personal history with Triple H, the two of them know each other very well. She said the two of them were once unstoppable and they can be again. Bischoff cut her off and begged her to stop. Stephanie cited that Triple H once told her how Bischoff said Triple H had no talent and no charisma. Bischoff said he was young at the time and didn't know what he had, but he still has a lot more experience that Stephanie. The two continued to bicker back and forth, until Triple H stepped up with his microphone. The Game said it would be easy to say \"screw you\" to either one of them. Triple H went to shake Bischoff's hand, but pulled it away. He said he would rather go with the devil he knows, rather than the one he doesn't know. Before he could go any further, though, Shawn Michaels came out to shake things up. HBK said the last thing he wanted to do was cause any trouble. He didn't want to get involved, but he remembered pledging to bring Triple H to the nWo. HBK said there's nobody in the world that Triple H is better friends with. HBK told his friend to imagine the two back together again, making Bischoff's life a living hell. Triple H said that was a tempting offer. He then turned and hugged HBK, making official his switch to RAW! Triple H and HBK left, and Bischoff gloated over his victory. Bischoff said the difference between the two of them is that he's got testicles and she doesn't. Stephanie whacked Bischoff on the side of the head and left!<br /><br />Match 7: Tag Team Championship Match Christian and Lance Storm vs Hollywood Hogan and Edge The match started with loud \"USA\" chants and with Hogan shoving Christian through the ropes and out of the ring. The Canadians took over from there. But Edge scored a kick to Christian's head and planted a facebuster on Storm to get the tag to Hogan. Hogan began to Hulk up and soon caught Christian with a big boot and a leg drop! Storm broke up the count and Christian tossed Hogan from the ring where Storm superkicked the icon. Edge tagged in soon after and dropped both opponents. He speared both of them into the corner turnbuckles, but missed a spear on Strom and hit the ref hard instead. Edge nailed a DDT, but the ref was down and could not count. Test raced down and took down Hogan then leveled Edge with a boot. Storm tried to get the pin, but Edge kicked out after two. Riksihi sprinted in to fend off Test, allowing Edge to recover and spear Storm. Christian distracted the ref, though, and Y2J dashed in and clocked Edge with the Tag Team Championship! Storm rolled over and got the pinfall to win the title! Winners and New Tag Team Champions: Christian and Lance Storm<br /><br />Match 8: WWE Undisputed Championship Triple Threat Match. The Rock vs Kurt Angle and the Undertaker Three of WWE's most successful superstars lined up against each other in a Triple Threat Match with the Undisputed Championship hanging in the balance. Taker and The Rock got face to face with Kurt Angle begging for some attention off to the side. He got attention in the form of a beat down form the two other men. Soon after, Taker spilled out of the ring and The Rock brawled with Angle. Angle gave a series of suplexes that took down Rock, but the Great One countered with a DDT that managed a two-count. The fight continued outside the ring with Taker coming to life and clotheslining Angle and repeatedly smacking The Rock. Taker and Rock got into it back into the ring, and Taker dropped The Rock with a sidewalk slam to get a two-count. Rock rebounded, grabbed Taker by the throat and chokeslammed him! Angle broke up the pin attempt that likely would have given The Rock the title. The Rock retaliated by latching on the ankle lock to Kurt Angle. Angle reversed the move and Rock Bottomed the People's Champion. Soon after, The Rock disposed of Angle and hit the People's Elbow on the Undertaker. Angle tried to take advantage by disabling the Great One outside the ring and covering Taker, who kicked out after a two count. Outside the ring, Rock took a big swig from a nearby water bottle and spewed the liquid into Taker's face to blind the champion. Taker didn't stay disabled for long, and managed to overpower Rock and turn his attention to Angle. Taker landed a guillotine leg drop onto Angle, laying on the ring apron. The Rock picked himself up just in time to break up a pin attempt on Kurt Angle. Taker nailed Rock with a DDT and set him up for a chokeslam. ANgle tried sneaking up with a steel chair, but Taker caught on to that tomfoolery and smacked it out of his hands. The referee got caught in the ensuing fire and didn't see Angle knock Taker silly with a steel chair. Angle went to cover Taker as The Rock lay prone, but the Dead Man somehow got his shoulder up. Angle tried to pin Rock, but he too kicked out. The Rock got up and landed Angle in the sharpshooter! Angle looked like he was about to tap, but Taker kicked The Rock out of the submission hold. Taker picked Rock up and crashed him with the Last Ride. While the Dead Man covered him for the win, Angle raced in and picked Taker up in the ankle lock! Taker went delirious with pain, but managed to counter. He picked Angle up for the last ride, but Angle put on a triangle choke! It looked like Taker was about to pass out, but The Rock broke Angle's hold only to find himself caught in the ankle lock. Rock got out of the hold and watched Taker chokeslam Angle. Rocky hit the Rock Bottom, but Taker refused to go down and kicked out. Angle whirled Taker up into the Angle Slam but was Rock Bottomed by the Great One and pinned! Winner and New WWE Champion: The Rock<br /><br />~Finally there is a decent PPV! Lately the PPV weren't very good, but this one was a winner. I give this PPV a A-<br /><br />\n"
     ]
    }
   ],
   "source": [
    "max_review = max(train_data, key=len)\n",
    "print(max_review)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470\n"
     ]
    }
   ],
   "source": [
    "# find the number of words in this review\n",
    "words = max_review.split()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dictionary is : 854\n",
      "\n",
      "the 167\n",
      "and 98\n",
      "to 85\n",
      "a 70\n",
      "with 41\n",
      "but 38\n",
      "The 31\n",
      "in 27\n",
      "up 26\n",
      "his 26\n",
      "of 24\n",
      "on 22\n",
      "Rock 22\n",
      "into 21\n",
      "Taker 20\n",
      "for 19\n",
      "Angle 18\n",
      "ring 17\n",
      "Bubba 16\n",
      "Triple 15\n",
      "Spike 14\n"
     ]
    }
   ],
   "source": [
    "# find the number of unique words used in the review\n",
    "d = {}\n",
    "for word in words:\n",
    "    if word not in d:\n",
    "        d[word] = 1\n",
    "    else:\n",
    "        d[word] += 1\n",
    "\n",
    "    \n",
    "print(\"Length of the dictionary is : \" + str(len(d)) + \"\\n\")\n",
    "i = 0\n",
    "for w in sorted(d, key=d.get, reverse=True):\n",
    "    print(w, d[w])\n",
    "    if i == 20:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longest review is 2470 word long and contains 854 words. The count vectoriser above uses the most common 200 words and so this model misses out on 654 other words from the review for its prediction of sentiment. The most common words are 'the', 'and', 'to', and 'a' with occurences between 70-167 for these. These do not aid the prediction of the model so this reinforces the potential use of stop word removal in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/dockreg/anaconda3/lib/python3.7/site-packages (22.0.4)\n",
      "Requirement already satisfied: setuptools in /Users/dockreg/anaconda3/lib/python3.7/site-packages (61.2.0)\n",
      "Requirement already satisfied: wheel in /Users/dockreg/anaconda3/lib/python3.7/site-packages (0.37.1)\n",
      "Requirement already satisfied: spacy in /Users/dockreg/anaconda3/lib/python3.7/site-packages (3.2.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (0.7.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (3.10.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy) (4.62.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m254.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (61.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dockreg/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy - english model - small\n",
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'‘m', 'an', 'five', 'could', 'they', 'three', 'there', 'around', 'against', 'latter', 'several', 'amongst', 'made', 'various', 'beforehand', 'still', 'its', 'a', 'indeed', 'mostly', 'hereafter', 'sometimes', 'to', 'bottom', 'somehow', 'here', 'been', 'back', 'as', '’m', 'enough', 'call', 'themselves', 'where', 'become', 'see', 'one', \"n't\", 'them', 'hundred', 'it', 'neither', 'or', 'whereby', 'whatever', 'among', 'wherein', 'she', 'and', 'has', 'nine', 'more', '’d', 'never', 'only', 'at', 'together', 'did', 'his', 'well', '’s', 'us', 'was', 'many', 'used', 'yourself', 'am', 'six', 'although', 'eight', 'while', 'he', 'yet', 'quite', 'about', 'beside', 'might', 'sixty', 'whether', 'otherwise', \"'d\", 'part', 'from', 'under', 'seem', 'herself', 'me', 'eleven', 'will', 'above', 'if', 'ever', 'hereby', 'thereafter', 'name', \"'s\", 'too', 'already', 'former', 'during', 'most', 'across', 'becomes', 'no', 'front', 'you', 'seemed', 'hers', 'formerly', 'each', 'forty', 'four', 'fifty', 'but', 'along', 'fifteen', 'over', 'do', 'less', 'are', 'may', 'also', 'therein', 'therefore', '‘re', 'unless', 'everyone', 'can', 'next', 'seems', 'had', 'side', 're', 'within', 'these', 'either', 'so', 'being', 'anything', 'though', 'thereupon', 'why', 'almost', 'were', 'n‘t', 'does', 'than', 'by', 'my', 'nor', 'some', 'empty', 'in', 'whereas', 'rather', 'say', 'moreover', 'cannot', 'afterwards', 'we', 'very', 'with', 'whenever', 'again', 'alone', 'hence', 'amount', 'due', 'throughout', 'onto', 'namely', 'the', 'nobody', 'get', 'anywhere', 'give', 'whose', 'thence', 'thereby', 'nothing', 'ours', 'least', 'whereafter', 'anyhow', '‘d', 'both', 'towards', 'whence', 'itself', 'hereupon', 'two', 'put', \"'ve\", 'since', 'below', 'yours', 'yourselves', 'twelve', 'another', 'whereupon', 'beyond', 'until', 'first', 'without', '‘ve', 'none', 'before', 'someone', 'latterly', 'anyone', 'herein', 'those', 'whoever', 'seeming', 'thus', 'upon', 'would', 'keep', 'up', 'else', 'ourselves', 'for', 'be', 'on', 'whom', 'her', 'same', 'full', 'once', 'becoming', 'after', '‘ll', 'noone', 'twenty', 'last', 'what', 'nevertheless', 'now', 'always', 'off', 'himself', 'not', 'often', 'whole', 'every', 'when', 'this', 'show', 'their', 'everywhere', 'move', 'something', '’ve', 'really', 'between', 'serious', 'have', 'regarding', 'ten', 'done', \"'ll\", 'everything', 'which', 'behind', 'anyway', \"'re\", 'take', 'i', 'sometime', 'except', 'thru', 'out', 'how', 'others', 'must', '’re', 'n’t', 'wherever', 'into', 'because', 'using', '‘s', 'became', 'go', 'via', 'our', 'much', 'top', '’ll', 'few', 'whither', 'meanwhile', 'even', 'own', 'besides', 'somewhere', 'make', 'mine', 'perhaps', 'through', 'further', 'then', 'just', 'elsewhere', 'that', 'is', 'your', 'nowhere', 'should', 'down', 'doing', 'please', 'any', 'other', 'ca', 'however', 'him', 'toward', 'myself', 'all', 'of', 'per', 'who', 'third', \"'m\", 'such'}\n"
     ]
    }
   ],
   "source": [
    "# print all of the stop words from this library\n",
    "print(sw_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the data before the removal of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list containing the reviews with all stop words removed\n",
    "stop_removed_train_data = []\n",
    "for item in train_data:\n",
    "    item = [word for word in item.split() if word.lower() not in sw_spacy]\n",
    "    item = ' '.join(item)\n",
    "    stop_removed_train_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rented CURIOUS-YELLOW video store controversy surrounded released 1967. heard seized U.S. customs tried enter country, fan films considered \"controversial\" myself.<br /><br />The plot centered young Swedish drama student named Lena wants learn life. particular wants focus attentions making sort documentary average Swede thought certain political issues Vietnam War race issues United States. asking politicians ordinary denizens Stockholm opinions politics, sex drama teacher, classmates, married men.<br /><br />What kills CURIOUS-YELLOW 40 years ago, considered pornographic. Really, sex nudity scenes far between, it\\'s shot like cheaply porno. countrymen mind find shocking, reality sex nudity major staple Swedish cinema. Ingmar Bergman, arguably answer good old boy John Ford, sex scenes films.<br /><br />I commend filmmakers fact sex shown film shown artistic purposes shock people money shown pornographic theaters America. CURIOUS-YELLOW good film wanting study meat potatoes (no pun intended) Swedish cinema. really, film doesn\\'t plot.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect stop word removed data\n",
    "stop_removed_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 142\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0].split()),len(stop_removed_train_data[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stop removed data has reduced the length of the review from 288 words to 142 words. This allows all words to be used in the CountVectoriser \n",
    "The new data set is now run through the logistic regression model to see if it has improved the accuracy of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# create an array of the stop word removed data\n",
    "vectorizer = CountVectorizer(analyzer='word',max_features=200,lowercase=True)\n",
    "features = vectorizer.fit_transform(stop_removed_train_data)\n",
    "features_nd = features.toarray()\n",
    "print(len(features_nd))\n",
    "print(len(features_nd[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80/20 train/test\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_nd,train_data_labels,train_size=0.8,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model.\n",
    "log_model = log_model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model on the validation set.\n",
    "y_pred = log_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7622\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on the validation set is the same for the stop word removed data as for the normal data. The test data is now used to understand if the accuracy of the system has increased based on the results with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/dockreg/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b23cfeb68a931a8d.arrow\n"
     ]
    }
   ],
   "source": [
    "# select test data\n",
    "test_dataset = raw_datasets['test'].shuffle(seed=42).select(range(1000))\n",
    "test_data = []\n",
    "test_data_labels = []\n",
    "for item in test_dataset:\n",
    "    test_data.append(item['text'])\n",
    "    test_data_labels.append(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed the stop words from the test data\n",
    "stop_removed_test_data = []\n",
    "for item in test_data:\n",
    "    item = [word for word in item.split() if word.lower() not in sw_spacy]\n",
    "    item = ' '.join(item)\n",
    "    stop_removed_test_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767\n"
     ]
    }
   ],
   "source": [
    "#Apply the model to the test data.\n",
    "\n",
    "test_pred=log_model.predict(vectorizer.transform(stop_removed_test_data).toarray())\n",
    "\n",
    "print(accuracy_score(test_pred,test_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model with the removal of stop words has resulted in the improvement in accuracy to ~77%.\n",
    "\n",
    "The next phase of this involves using named entity recognition to mask named entities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Named entity recognition is used in this notebook to attempt to improve the accuracy of the model. The thought behind this is that certain actors, directors, organisations, or places from the training data may be used in a negative review without that word being fairly summarised as negative. Certain words such as bad, awful, or horrible have a negative connotation to them where Harry Potter, Shrek, or Gotham City should not be labelled as positive or negative as that varies from viewer to viewer. The view is that by removing subjective named entities, the model is better able to predict sentiment based on the other elements of the language. This theory is put into practive below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.add_pipe(\"merge_entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create named entity masked data\n",
    "ner_train_data = []\n",
    "for item in train_data:\n",
    "    doc = en(item)\n",
    "    ner = ' '.join([t.text if not t.ent_type_ else t.ent_type_ for t in doc])\n",
    "    ner_train_data.append(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" WORK_OF_ART \" is a risible and pretentious steaming pile . It does n\\'t matter what one \\'s political views are because this film can hardly be taken seriously on any level . As for the claim that frontal male nudity is an automatic NC-17 , that is n\\'t true . I \\'ve seen R - rated films with male nudity . Granted , they only offer some fleeting views , but where are the R - rated films with gaping vulvas and flapping labia ? Nowhere , because they do n\\'t exist . The same goes for those crappy cable shows : schlongs swinging in the breeze but not a clitoris in sight . And those pretentious indie movies like PRODUCT , in which we \\'re treated to the site of PERSON throbbing johnson , but not a trace of pink visible on PERSON . Before crying ( or implying ) \" double - standard \" in matters of nudity , the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women : there are no genitals on display when actresses appears nude , and the same can not be said for a man . In fact , you generally wo n\\'t see female genitals in an NORP film in anything short of porn or explicit erotica . This alleged double - standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women \\'s bodies .'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ner masked data has removed all instances of named entities and has replaced them with masked version of the type of named entity.\n",
    "\n",
    "In the example above the title of the film has been masked as 'WORK_OF_ART'.\n",
    "\n",
    "This new masked data is now turned into a vector array for training and then validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "200\n",
      "0.7648\n"
     ]
    }
   ],
   "source": [
    "# create vector with ner data for training\n",
    "vectorizer = CountVectorizer(analyzer='word',max_features=200,lowercase=True)\n",
    "features = vectorizer.fit_transform(ner_train_data)\n",
    "features_nd = features.toarray()\n",
    "print(len(features_nd))\n",
    "print(len(features_nd[0]))\n",
    "\n",
    "# split ner data into train/validate \n",
    "X_train, X_val, y_train, y_val = train_test_split(features_nd,train_data_labels,train_size=0.8,random_state=123)\n",
    "\n",
    "# create the model\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Train the model.\n",
    "log_model = log_model.fit(X=X_train,y=y_train)\n",
    "\n",
    "# Test the model on the validation set.\n",
    "y_pred = log_model.predict(X_val)\n",
    "\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on the validation set is 76%. This is very similar to the original models accuracy of 77% on the validation set. The model is now tested with the ner test data and the accuracy is inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_test_data = []\n",
    "for item in test_data:\n",
    "    doc = en(item)\n",
    "    ner = ' '.join([t.text if not t.ent_type_ else t.ent_type_ for t in doc])\n",
    "    ner_test_data.append(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746\n"
     ]
    }
   ],
   "source": [
    "#Apply the model to the test data.\n",
    "test_pred=log_model.predict(vectorizer.transform(ner_test_data).toarray())\n",
    "\n",
    "print(accuracy_score(test_pred,test_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The resulting accuracy of the model is 75%. Named entity recognition did not aid in the improvement of the model. Further inspection into selected named entities such as organisations or countries would be of interest in the future to see if there is any method in which the use of named entities improves the predictive capabilities of the logistic regression sentiment classification model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "imdb-lr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d9e8798cb9a49c49e223f95ffe42472": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b94d8e360a44b6f83731af68677906e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba2e4cdda6a34b19b3f6715a7610404b",
       "IPY_MODEL_5fb61b5ce17f478888f05d9b664f5712",
       "IPY_MODEL_cdd09b420fc54b7583fb32a25c002666"
      ],
      "layout": "IPY_MODEL_8be58c388ed84ceb901afb141a7b9c35"
     }
    },
    "5fb61b5ce17f478888f05d9b664f5712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c5797f269fa4c22b76680d4c17510c3",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d9e8798cb9a49c49e223f95ffe42472",
      "value": 3
     }
    },
    "6c5797f269fa4c22b76680d4c17510c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8be58c388ed84ceb901afb141a7b9c35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aecef84787f74ca484558d5e790fd736": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4607a3bc9544578829f101921518328": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba2e4cdda6a34b19b3f6715a7610404b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aecef84787f74ca484558d5e790fd736",
      "placeholder": "​",
      "style": "IPY_MODEL_bb006df01bdf4635a19524c409ae2a44",
      "value": "100%"
     }
    },
    "bb006df01bdf4635a19524c409ae2a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdd09b420fc54b7583fb32a25c002666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4607a3bc9544578829f101921518328",
      "placeholder": "​",
      "style": "IPY_MODEL_ee93ee8a3d414c72a70b35705083e8e6",
      "value": " 3/3 [00:00&lt;00:00,  6.81it/s]"
     }
    },
    "ee93ee8a3d414c72a70b35705083e8e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
